#!/bin/bash
#SBATCH --output=./res/segmentation.out
#SBATCH --open-mode=append
#SBATCH --mem-per-cpu=10GB
#SBATCH --time=2-23:00:00
#SBATCH --job-name=seg
#SBATCH --partition=your_hpc_nodes_partition
#SBATCH --account=your_hpc_account
#SBATCH --nodes=10
#SBATCH --ntasks=10
#SBATCH --cpus-per-task=20
#SBATCH --mail-type=END


# Activate the environment
source $HOME/miniconda3/etc/profile.d/conda.sh
conda activate $HOME/miniconda3/envs/u19

# Define config file
# "LOS_chr22_AA_seg-1_overlap0.yaml"
# "LOS_chr22_AA_seg128_overlap16.yaml"
# "LOS_chr22_CA_seg-1_overlap0.yaml"
# "LOS_chr22_CA_seg128_overlap16.yaml"
# "HLA_chr6_ALL_seg128_overlap64.yaml"
CONF_FILE="1KGP_chr22_ALL_seg128_overlap16.yaml"
ENABLE_SEG=False

# Ensure no thread oversubscription
export OMP_NUM_THREADS=1
unset SLURM_TRES_PER_TASK

# Start overall timing
overall_starttime=$(date +'%Y-%m-%d %H:%M:%S')

# Process all random states in a single run
# The Python script will handle task distribution
echo "Processing all random states in parallel"
echo "Started at: $(date +'%Y-%m-%d %H:%M:%S')"

# Run the Python script using srun to handle all random states
starttime=$(date +'%Y-%m-%d %H:%M:%S')
srun python segmenting.py --configFile configs/${CONF_FILE} --createFilteredSNPs ${ENABLE_SEG}
endtime=$(date +'%Y-%m-%d %H:%M:%S')

# Report timing
start_seconds=$(date --date="$starttime" +%s)
end_seconds=$(date --date="$endtime" +%s)
total_seconds=$((end_seconds - start_seconds))
hours=$((total_seconds / 3600))
minutes=$(((total_seconds % 3600) / 60))
echo "Total running time: ${hours}h ${minutes}m"
